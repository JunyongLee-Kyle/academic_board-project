{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LPIPS-sort.ipynb",
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JunyongLee-Kyle/academic_board-project/blob/master/LPIPS_sort.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVtQuQZCoMaf"
      },
      "source": [
        "#LPIPS\n",
        "\n",
        "LPIPS is a library that tests for the distance between two images using a deep neural network classifier.\n",
        "\n",
        "A demo of the concepts behind this notebook is available on [YouTube](https://youtu.be/wTw33t6K1uk).\n",
        "\n",
        "If you find this notebook useful, consider signing up for my [Patreon](https://www.patreon.com/bustbright) or [YouTube channel](https://www.youtube.com/channel/UCaZuPdmZ380SFUMKHVsv_AA/join). You can also send me a one-time payment on [Venmo](https://venmo.com/Derrick-Schultz)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pg6ZMtLjo8D9"
      },
      "source": [
        "#check to see what GPU we get assigned\n",
        "!nvidia-smi -L"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3yK1mPqpCJB"
      },
      "source": [
        "#install LPIPS\n",
        "!git clone https://github.com/richzhang/PerceptualSimilarity\n",
        "!pip install lpips\n",
        "# !pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWNXUlMy49nE"
      },
      "source": [
        "Let’s download horse2zebra to use in this demo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEYWAlYrCGoF"
      },
      "source": [
        "!gdown --id 1SJNZ1ETLwF4qsSgFd0R2M4JAooX2uvGi -O /content/horse2zebra.zip\n",
        "!unzip /content/horse2zebra.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkadpILE8_2q"
      },
      "source": [
        "#Images\n",
        "from IPython.display import Image, display\n",
        "\n",
        "listOfImageNames = ['/content/horse2zebra/horse/n02381460_1000.jpg',\n",
        "                    '/content/horse2zebra/horse/n02381460_1001.jpg',\n",
        "                    '/content/horse2zebra/zebra/n02391049_100.jpg',\n",
        "                    '/content/horse2zebra/zebra/n02391049_1000.jpg',\n",
        "                    ]\n",
        "\n",
        "for imageName in listOfImageNames:\n",
        "    display(Image(filename=imageName, width=400))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17Ko5iffom_J"
      },
      "source": [
        "## Compare two images\n",
        "The below example will return the distance between two specified images\n",
        "\n",
        "* `p0`: path to the first image\n",
        "* `p1`: path to the second image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-iEEppSuCcb"
      },
      "source": [
        "##Find all images in a folder within a certain distance of an image\n",
        "\n",
        "I’ve written some code into my dataset-tools library to find all the images that are <= to a certain distance using a starting image.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python ./PerceptualSimilarity/lpips_2imgs.py \\\n",
        "    -p0 /content/variation_1.png \\\n",
        "    -p1 /content/variation_2.png  \\\n",
        "    --use_gpu"
      ],
      "metadata": {
        "id": "fELk4JPcBfMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python ./PerceptualSimilarity/lpips_1dir_allpairs.py \\\n",
        "-d /content/drive/MyDrive/Model_Testing/stabilityai_sdxl-turbo/Multiple_Objects/Spices_in_jars_next_to_a_cooking_book \\\n",
        "-o /content/result.txt \\\n",
        "--all-pairs \\\n",
        "--use_gpu"
      ],
      "metadata": {
        "id": "oxgffLonUv2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python ./PerceptualSimilarity/lpips_1dir_allpairs.py \\\n",
        "-d /content/drive/MyDrive/Model_Testing/stabilityai_stable-diffusion-2-1-base/Multiple_Objects/Spices_in_jars_next_to_a_cooking_book \\\n",
        "-o /content/result.txt \\\n",
        "--all-pairs \\\n",
        "--use_gpu"
      ],
      "metadata": {
        "id": "NIL6BrOU1Mtb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python ./PerceptualSimilarity/lpips_2dirs.py \\\n",
        "-d0 /content/drive/MyDrive/Model_Testing/stabilityai_stable-diffusion-2-1-base/Multiple_Objects/Spices_in_jars_next_to_a_cooking_book \\\n",
        "-d1 /content/drive/MyDrive/Model_Testing/stabilityai_stable-diffusion-2-1-base/Multiple_Objects/Spices_in_jars_next_to_a_cooking_book \\\n",
        "-o /content/example_dists.txt \\\n",
        "--use_gpu"
      ],
      "metadata": {
        "id": "iCxIuphxvh4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PQb9FrZpMtl"
      },
      "source": [
        "!python ./PerceptualSimilarity/lpips_2imgs.py \\\n",
        "    -p0 /content/variation_1.png \\\n",
        "    -p1 /content/variation_2.png  \\\n",
        "    --use_gpu\n",
        "!python ./PerceptualSimilarity/lpips_2imgs.py \\\n",
        "    -p0 /content/variation_1.png \\\n",
        "    -p1 /content/variation_3.png  \\\n",
        "    --use_gpu\n",
        "!python ./PerceptualSimilarity/lpips_2imgs.py \\\n",
        "    -p0 /content/variation_1.png \\\n",
        "    -p1 /content/variation_4.png  \\\n",
        "    --use_gpu\n",
        "!python ./PerceptualSimilarity/lpips_2imgs.py \\\n",
        "    -p0 /content/variation_1.png \\\n",
        "    -p1 /content/variation_5.png  \\\n",
        "    --use_gpu\n",
        "!python ./PerceptualSimilarity/lpips_2imgs.py \\\n",
        "    -p0 /content/variation_2.png \\\n",
        "    -p1 /content/variation_3.png  \\\n",
        "    --use_gpu\n",
        "!python ./PerceptualSimilarity/lpips_2imgs.py \\\n",
        "    -p0 /content/variation_2.png \\\n",
        "    -p1 /content/variation_4.png  \\\n",
        "    --use_gpu\n",
        "!python ./PerceptualSimilarity/lpips_2imgs.py \\\n",
        "    -p0 /content/variation_2.png \\\n",
        "    -p1 /content/variation_5.png  \\\n",
        "    --use_gpu\n",
        "!python ./PerceptualSimilarity/lpips_2imgs.py \\\n",
        "    -p0 /content/variation_3.png \\\n",
        "    -p1 /content/variation_4.png  \\\n",
        "    --use_gpu\n",
        "!python ./PerceptualSimilarity/lpips_2imgs.py \\\n",
        "    -p0 /content/variation_3.png \\\n",
        "    -p1 /content/variation_5.png  \\\n",
        "    --use_gpu\n",
        "!python ./PerceptualSimilarity/lpips_2imgs.py \\\n",
        "    -p0 /content/variation_4.png \\\n",
        "    -p1 /content/variation_5.png  \\\n",
        "    --use_gpu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Drastic change"
      ],
      "metadata": {
        "id": "OqadPlXBOWcw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python ./PerceptualSimilarity/lpips_2imgs.py \\\n",
        "    -p0 /content/variation_1.png \\\n",
        "    -p1 /content/black.jpg \\\n",
        "    --use_gpu\n",
        "!python ./PerceptualSimilarity/lpips_2imgs.py \\\n",
        "    -p0 /content/variation_2.png \\\n",
        "    -p1 /content/black.jpg \\\n",
        "    --use_gpu\n",
        "!python ./PerceptualSimilarity/lpips_2imgs.py \\\n",
        "    -p0 /content/variation_3.png \\\n",
        "    -p1 /content/black.jpg \\\n",
        "    --use_gpu\n",
        "!python ./PerceptualSimilarity/lpips_2imgs.py \\\n",
        "    -p0 /content/variation_4.png \\\n",
        "    -p1 /content/black.jpg \\\n",
        "    --use_gpu\n",
        "!python ./PerceptualSimilarity/lpips_2imgs.py \\\n",
        "    -p0 /content/variation_5.png \\\n",
        "    -p1 /content/black.jpg \\\n",
        "    --use_gpu"
      ],
      "metadata": {
        "id": "RRnaqFwpM3dg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VdiO7XolX7g4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ykaMhWqP1Udp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpBwmYfgw9RP"
      },
      "source": [
        "#install dataset-tools\n",
        "%cd /content/\n",
        "!git clone https://github.com/dvschultz/dataset-tools\n",
        "%cd dataset-tools/\n",
        "!pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vr5bEtIayuVO"
      },
      "source": [
        "here’s the entire command we’ll use:\n",
        "\n",
        "* `-i` path to input folder\n",
        "* `-o` where to put all the files that match\n",
        "* `--start_img` feed the model a starting image\n",
        "* `--max_dist` provide a max distance (anything higher than this value will be excluded)\n",
        "* `--net`: what pre-trained network to use (options: `vgg`, `alex`, `squeeze`)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WS9xgmdCBebb"
      },
      "source": [
        "%cd /content/dataset-tools/\n",
        "!python sort.py -i /content/horse2zebra/zebra -o /content/zebra-sort/ \\\n",
        "    -p lpips \\\n",
        "    --start_img /content/horse2zebra/zebra/n02391049_101.jpg \\\n",
        "    --max_dist 0.75 \\\n",
        "    --net 'alex' \\\n",
        "    --use_gpu -v"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggekkzANCoHg"
      },
      "source": [
        "%cd /content/horse2zebra/zebra\n",
        "\n",
        "!find . -type f | wc -l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcFH8kXFHlLD"
      },
      "source": [
        "%cd /content/zebra-sort\n",
        "\n",
        "!find . -type f | wc -l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAky2jqfHraL"
      },
      "source": [
        "!rm -r /content/zebra-sort"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFp1MrlEVmUt"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}